{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# AskQE Pipeline - Qwen2.5-3B-Instruct Baseline\n",
                "\n",
                "This notebook runs the complete AskQE pipeline using the **Qwen/Qwen2.5-3B-Instruct** model.\n",
                "All results are saved in `results Qwen3B baseline/` folder.\n",
                "\n",
                "**Note:** Models are cached on Google Drive for faster subsequent runs."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "drive-header",
            "metadata": {},
            "source": [
                "## 0. Mount Google Drive & Configure Model Cache\n",
                "\n",
                "This section mounts Google Drive and configures the model cache directory to avoid re-downloading models on each run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "drive-mount",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive (only works in Colab)\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Check if running in Colab\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if IN_COLAB:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    # Set model cache directory on Google Drive\n",
                "    DRIVE_CACHE_DIR = '/content/drive/MyDrive/AskQE_Models_Cache'\n",
                "    os.makedirs(DRIVE_CACHE_DIR, exist_ok=True)\n",
                "    \n",
                "    # Configure Hugging Face cache\n",
                "    os.environ['HF_HOME'] = DRIVE_CACHE_DIR\n",
                "    os.environ['TRANSFORMERS_CACHE'] = os.path.join(DRIVE_CACHE_DIR, 'transformers')\n",
                "    os.environ['SENTENCE_TRANSFORMERS_HOME'] = os.path.join(DRIVE_CACHE_DIR, 'sentence_transformers')\n",
                "    \n",
                "    print(f'Model cache directory: {DRIVE_CACHE_DIR}')\n",
                "else:\n",
                "    print('Not running in Colab - using default cache directories')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-header",
            "metadata": {},
            "source": [
                "## Setup - Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Install dependencies\n",
                "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'transformers', 'torch', 'accelerate', 'nltk', 'sentence-transformers', 'sacrebleu', 'textstat'], check=True)\n",
                "\n",
                "# Get project root\n",
                "if IN_COLAB:\n",
                "    # Clone repo if not present\n",
                "    if not os.path.exists('/content/askqe'):\n",
                "        subprocess.run(['git', 'clone', 'https://github.com/Simone280802/AskQE_DNLP_2025-2026.git', '/content/askqe'], check=True)\n",
                "    PROJECT_ROOT = '/content/askqe'\n",
                "else:\n",
                "    PROJECT_ROOT = os.getcwd()\n",
                "\n",
                "RESULTS_DIR = os.path.join(PROJECT_ROOT, 'results Qwen3B baseline')\n",
                "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
                "\n",
                "print(f'Project root: {PROJECT_ROOT}')\n",
                "print(f'Results directory: {RESULTS_DIR}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "models-header",
            "metadata": {},
            "source": [
                "## Pre-download Models\n",
                "\n",
                "Download all models needed for the pipeline. These will be saved to Google Drive and reused in future runs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "models-download",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import torch\n",
                "\n",
                "print('=== Downloading/Loading Models ===')\n",
                "print('This may take a while on first run, but will be cached on Drive for future use.\\n')\n",
                "\n",
                "# List of models to download\n",
                "MODELS = {\n",
                "    'qwen': 'Qwen/Qwen2.5-3B-Instruct',\n",
                "    'sbert': 'sentence-transformers/all-MiniLM-L6-v2',\n",
                "    'qa_model': 'potsawee/longformer-large-4096-answerable-squad2'  # For answerability evaluation\n",
                "}\n",
                "\n",
                "# Download Qwen model\n",
                "print(f\"[1/3] Loading {MODELS['qwen']}...\")\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODELS['qwen'])\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODELS['qwen'],\n",
                "    torch_dtype=torch.bfloat16,\n",
                "    device_map='auto'\n",
                ")\n",
                "print(f\"      ✓ Qwen model loaded\")\n",
                "\n",
                "# Free memory - model will be reloaded when needed\n",
                "del model, tokenizer\n",
                "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
                "\n",
                "# Download SBERT model\n",
                "print(f\"[2/3] Loading {MODELS['sbert']}...\")\n",
                "sbert_model = SentenceTransformer(MODELS['sbert'])\n",
                "print(f\"      ✓ SBERT model loaded\")\n",
                "del sbert_model\n",
                "\n",
                "# Download QA model for answerability\n",
                "print(f\"[3/3] Loading {MODELS['qa_model']}...\")\n",
                "try:\n",
                "    qa_tokenizer = AutoTokenizer.from_pretrained(MODELS['qa_model'])\n",
                "    print(f\"      ✓ QA model loaded\")\n",
                "    del qa_tokenizer\n",
                "except Exception as e:\n",
                "    print(f\"      ⚠ Could not load QA model: {e}\")\n",
                "\n",
                "print('\\n=== All models cached! ===')\n",
                "if IN_COLAB:\n",
                "    print(f'Models saved to: {DRIVE_CACHE_DIR}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "qg-header",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 1. Question Generation (QG)\n",
                "\n",
                "Generate questions for each variant: vanilla, atomic, and semantic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qg-vanilla",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run QG for vanilla prompt\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'QG', 'code'))\n",
                "output_path = os.path.join(RESULTS_DIR, 'QG', 'vanilla_qwen-3b.jsonl')\n",
                "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "subprocess.run([sys.executable, '-u', 'qwen-3b.py', '--output_path', output_path, '--prompt', 'vanilla'], check=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qg-atomic",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run QG for atomic prompt\n",
                "output_path = os.path.join(RESULTS_DIR, 'QG', 'atomic_qwen-3b.jsonl')\n",
                "subprocess.run([sys.executable, '-u', 'qwen-3b.py', '--output_path', output_path, '--prompt', 'atomic'], check=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qg-semantic",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run QG for semantic prompt\n",
                "output_path = os.path.join(RESULTS_DIR, 'QG', 'semantic_qwen-3b.jsonl')\n",
                "subprocess.run([sys.executable, '-u', 'qwen-3b.py', '--output_path', output_path, '--prompt', 'semantic'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "qa-header",
            "metadata": {},
            "source": [
                "## 2. Question Answering (QA)\n",
                "\n",
                "Answer questions based on source sentences and backtranslated MT."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qa-source",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run QA based on source sentences\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'QA', 'code'))\n",
                "qg_input = os.path.join(RESULTS_DIR, 'QG', 'vanilla_qwen-3b.jsonl')\n",
                "output_path = os.path.join(RESULTS_DIR, 'QA', 'source', 'qa_source.jsonl')\n",
                "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "subprocess.run([sys.executable, '-u', 'qwen-3b.py', '--output_path', output_path, '--sentence_type', 'source', '--qg_input_path', qg_input], check=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qa-bt",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run QA based on backtranslated MT\n",
                "qg_input = os.path.join(RESULTS_DIR, 'QG', 'vanilla_qwen-3b.jsonl')\n",
                "output_path = os.path.join(RESULTS_DIR, 'QA', 'bt', 'qa_bt.jsonl')\n",
                "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "subprocess.run([sys.executable, '-u', 'qwen-3b.py', '--output_path', output_path, '--sentence_type', 'bt', '--qg_input_path', qg_input], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "biomqm-header",
            "metadata": {},
            "source": [
                "## 3. BioMQM Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "biomqm-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run BioMQM pipeline\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'biomqm', 'askqe'))\n",
                "output_path = os.path.join(RESULTS_DIR, 'biomqm', 'askqe_qg_qwen3b.jsonl')\n",
                "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "subprocess.run([sys.executable, '-u', 'qwen-3b.py', '--output_path', output_path, '--prompt', 'atomic'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eval-header",
            "metadata": {},
            "source": [
                "## 4. Evaluation Metrics\n",
                "\n",
                "### 4.1 SBERT (Sentence-BERT Cosine Similarity)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eval-sbert",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run SBERT evaluation\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'evaluation', 'sbert'))\n",
                "output_file = os.path.join(RESULTS_DIR, 'evaluation', 'sbert', 'qwen-3b.csv')\n",
                "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
                "subprocess.run([sys.executable, 'sbert.py', '--model', 'qwen-3b', '--output_file', output_file], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "string-header",
            "metadata": {},
            "source": [
                "### 4.2 String Comparison (F1, EM, BLEU, chrF)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eval-string",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run String Comparison evaluation\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'evaluation', 'string-comparison'))\n",
                "subprocess.run([sys.executable, 'string_comparison.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "qe-header",
            "metadata": {},
            "source": [
                "## 5. Baseline Metrics (QE)\n",
                "\n",
                "### 5.1 BT-Score (BERTScore on backtranslation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qe-btscore",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run BT-Score\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'evaluation', 'bt-score'))\n",
                "subprocess.run([sys.executable, 'run_bt.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "xcomet-header",
            "metadata": {},
            "source": [
                "### 5.2 xCOMET-QE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "qe-xcomet",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run xCOMET-QE\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'evaluation', 'xcomet-qe'))\n",
                "subprocess.run([sys.executable, 'xcomet.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "desiderata-header",
            "metadata": {},
            "source": [
                "## 6. Desiderata Evaluation (Question Quality)\n",
                "\n",
                "### 6.1 Empty Questions Count"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "des-empty",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Empty Questions evaluation\n",
                "os.chdir(os.path.join(PROJECT_ROOT, 'evaluation', 'desiderata'))\n",
                "subprocess.run([sys.executable, 'i_avg_questions.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dup-header",
            "metadata": {},
            "source": [
                "### 6.2 Duplicate Questions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "des-dup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Duplicate Questions evaluation\n",
                "subprocess.run([sys.executable, 'i_duplicate.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "div-header",
            "metadata": {},
            "source": [
                "### 6.3 Diversity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "des-div",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Diversity evaluation\n",
                "subprocess.run([sys.executable, 'i_diversity.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ans-header",
            "metadata": {},
            "source": [
                "### 6.4 Answerability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "des-ans",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Answerability evaluation\n",
                "subprocess.run([sys.executable, 'q_answerability.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "read-header",
            "metadata": {},
            "source": [
                "### 6.5 Readability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "des-read",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Readability evaluation\n",
                "subprocess.run([sys.executable, 'q_readability.py'], check=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "complete-header",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Pipeline Complete!\n",
                "\n",
                "All results are saved in the `results Qwen3B baseline/` folder."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}